{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge\n",
    "\n",
    "Another approach to identifying fraudulent transactions is to look for outliers in the data. Standard deviation or quartiles are often used to detect outliers. Using this starter notebook, code two Python functions:\n",
    "\n",
    "* One that uses standard deviation to identify anomalies for any cardholder.\n",
    "\n",
    "* Another that uses interquartile range to identify anomalies for any cardholder.\n",
    "\n",
    "## Identifying Outliers using Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sqlalchemy import create_engine\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a connection to the database\n",
    "# engine = create_engine(\"postgresql://postgres:postgres@localhost:5432/fraud_detection\")\n",
    "engine = create_engine(\"postgresql://postgres:postgres@localhost:5432/HW7\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_customer_transaction (in_custid='all'):\n",
    "    #connect to database and retrieve customers transactions\n",
    "    #get customer data\n",
    "    # if in_custid = all, then retun all customers\n",
    "    # otherwise return customer with matching id\n",
    "    #read the data all card from database\n",
    "\n",
    "  \n",
    "    query = \"\"\"\n",
    "    SELECT cc.cardholder_id as cardholder, tr.date as hour, tr.amount\n",
    "    FROM credit_card cc\n",
    "    Left join transaction tr\n",
    "    ON (cc.card = tr.card); \n",
    "    \"\"\"\n",
    "    all_card_df = pd.read_sql(query, engine)\n",
    "    if in_custid  == 'all':\n",
    "        return all_card_df\n",
    "    elif in_custid in range (all_card_df['cardholder'].min(), all_card_df['cardholder'].max()):\n",
    "        # get matching id if it is in valid range.\n",
    "        card_hold_df = all_card_df[all_card_df['cardholder'] == in_custid]\n",
    "        return card_hold_df\n",
    "    else:\n",
    "        # empty datafram\n",
    "        return (pd.DataFrame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to delete\n",
    "cust_df = get_customer_transaction ()\n",
    "mean_cust = cust_df['amount'].mean()\n",
    "std_cust = cust_df['amount'].std()\n",
    "\n",
    "outlier_df = cust_df.loc[(cust_df['amount'] > (mean_cust + 2 * std_cust)) | (cust_df['amount'] < (mean_cust - 2 * std_cust))]\n",
    "outlier_df\n",
    "\n",
    "cust_df['cardholder'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write function that locates outliers using standard deviation\n",
    "def find_std_anamoly (in_cust_id):\n",
    "#     in_cardholder is the card holder id\n",
    "#     function to make SQL sql query\n",
    "#     retrieve transactions for that user\n",
    "#     compute outliers for that customer.\n",
    "\n",
    "# read the data from daabase.\n",
    "# df.loc[(df['column_name'] >= A) & (df['column_name'] <= B)]\n",
    "    cust_df = get_customer_transaction (in_cust_id)\n",
    "    #find mean and mean and standard deve.\n",
    "    mean_cust = cust_df['amount'].mean()\n",
    "    std_cust = cust_df['amount'].std()\n",
    "    #find anamolie\n",
    "    outlier_df =  cust_df.loc[(cust_df['amount'] > (mean_cust + 2 * std_cust)) | (cust_df['amount'] < (mean_cust - 2 * std_cust))]\n",
    "    \n",
    "    return outlier_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to find three random card holder\n",
    "#### find maximum and minimum card holder number \n",
    "#### generate 3 random numumber in range \n",
    "#### find get anamoly in that range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anamolies for cardhoder 7\n",
      "\n",
      "      cardholder                hour  amount\n",
      "27             7 2018-01-04 03:05:18  1685.0\n",
      "484            7 2018-02-19 16:00:43  1072.0\n",
      "1079           7 2018-04-18 23:23:29  1086.0\n",
      "2142           7 2018-08-07 11:07:32  1449.0\n",
      "3327           7 2018-12-13 15:51:59  2249.0\n",
      "3379           7 2018-12-18 17:20:33  1296.0\n",
      "anamolies for cardhoder 9\n",
      "\n",
      "      cardholder                hour  amount\n",
      "613            9 2018-03-04 15:50:53  1534.0\n",
      "1578           9 2018-06-10 04:54:27  1795.0\n",
      "2575           9 2018-09-25 23:23:21  1095.0\n",
      "2703           9 2018-10-07 18:29:20  1179.0\n",
      "3389           9 2018-12-19 16:10:03  1724.0\n",
      "anamolies for cardhoder 10\n",
      "\n",
      "      cardholder                hour  amount\n",
      "2313          10 2018-08-28 07:17:14   20.71\n"
     ]
    }
   ],
   "source": [
    "# Find anomalous transactions for 3 random card holders\n",
    "all_card_holder_df = get_customer_transaction()\n",
    "\n",
    "# get random sample in range of minumum cardholder id, and max cardholder id\n",
    "card_holder_sample =  random.sample(range(all_card_holder_df['cardholder'].min(), all_card_holder_df['cardholder'].max() +1), k=3)\n",
    "\n",
    "#loop thrugh range and print results\n",
    "#perhaps I could write a different function to work the data frame instead?? \n",
    "#function already exists, so goal is to finish homework :) \n",
    "for car_holder in card_holder_sample:\n",
    "    print (f\"anamolies for cardhoder {car_holder}\\n\")\n",
    "    print(find_std_anamoly(car_holder))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Outliers Using Interquartile Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function that locates outliers using interquartile range\n",
    "\n",
    "def find_int_quart_anamoly (in_cust_id):\n",
    "#     in_cardholder is the card holder id\n",
    "#     function to make SQL sql query\n",
    "#     retrieve transactions for that user\n",
    "#     compute outliers for that customer.\n",
    "\n",
    "# read the data from daabase.\n",
    "# df.loc[(df['column_name'] >= A) & (df['column_name'] <= B)]\n",
    "    cust_df = get_customer_transaction (in_cust_id)\n",
    "    #find mean and mean and standard deve.\n",
    "    q25, q75 = np.percentile(cust_df['amount'], 25), np.percentile(cust_df['amount'], 75)\n",
    "#     mean_cust = cust_df['amount'].mean()\n",
    "#     std_cust = cust_df['amount'].std()\n",
    "    #find anamolie\n",
    "    outlier_df =  cust_df.loc[(cust_df['amount'] > (q75)) | (cust_df['amount'] < (q25))]\n",
    "    \n",
    "    return outlier_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interquartile anamolies for cardhoder 2\n",
      "\n",
      "      cardholder                hour  amount\n",
      "44             2 2018-01-06 02:16:41    1.33\n",
      "57             2 2018-01-07 15:10:27   17.29\n",
      "141            2 2018-01-16 06:29:35   17.64\n",
      "333            2 2018-02-03 18:05:39    1.41\n",
      "369            2 2018-02-08 05:12:18   18.32\n",
      "373            2 2018-02-08 12:15:41   15.39\n",
      "548            2 2018-02-26 01:52:16    1.01\n",
      "560            2 2018-02-27 08:27:00   18.52\n",
      "631            2 2018-03-05 15:43:47   17.06\n",
      "634            2 2018-03-06 04:01:25    4.10\n",
      "690            2 2018-03-10 08:52:09   13.53\n",
      "693            2 2018-03-10 19:52:29    4.13\n",
      "711            2 2018-03-12 05:07:34    3.79\n",
      "742            2 2018-03-15 06:41:30   15.24\n",
      "800            2 2018-03-20 17:15:15    1.64\n",
      "883            2 2018-03-29 20:01:40   18.62\n",
      "912            2 2018-04-01 11:54:51    1.08\n",
      "1179           2 2018-04-29 18:35:27    0.70\n",
      "1277           2 2018-05-10 00:19:48    3.42\n",
      "1297           2 2018-05-12 14:28:04   18.90\n",
      "1302           2 2018-05-12 19:53:37    3.31\n",
      "1397           2 2018-05-22 22:34:52    1.19\n",
      "1413           2 2018-05-24 20:39:06    1.76\n",
      "1445           2 2018-05-28 07:57:39   15.96\n",
      "1487           2 2018-06-01 11:31:13   14.24\n",
      "1497           2 2018-06-02 19:39:36   15.95\n",
      "1526           2 2018-06-05 11:13:42   16.96\n",
      "1649           2 2018-06-18 19:37:57    1.67\n",
      "1653           2 2018-06-19 02:45:45   17.25\n",
      "1817           2 2018-07-05 17:19:48    3.43\n",
      "1825           2 2018-07-06 03:02:41   16.99\n",
      "1855           2 2018-07-08 14:50:38    3.13\n",
      "2055           2 2018-07-28 03:34:44   17.16\n",
      "2123           2 2018-08-05 14:41:31    4.09\n",
      "2132           2 2018-08-06 16:17:07   16.55\n",
      "2252           2 2018-08-19 05:06:51   19.51\n",
      "2295           2 2018-08-26 05:44:04    2.74\n",
      "2466           2 2018-09-15 04:53:10   15.21\n",
      "2480           2 2018-09-16 17:27:47   17.72\n",
      "2519           2 2018-09-20 19:13:12    3.05\n",
      "2523           2 2018-09-21 01:57:52    1.58\n",
      "2559           2 2018-09-25 03:08:58    3.92\n",
      "2642           2 2018-10-02 18:48:15    1.17\n",
      "2700           2 2018-10-07 11:21:08    2.92\n",
      "2862           2 2018-10-24 09:56:38   16.84\n",
      "2903           2 2018-10-28 02:29:29    2.89\n",
      "2926           2 2018-10-30 09:45:03   16.64\n",
      "3045           2 2018-11-11 12:11:32    2.25\n",
      "3079           2 2018-11-15 04:26:02   16.40\n",
      "3323           2 2018-12-13 06:21:43   19.36\n",
      "interquartile anamolies for cardhoder 17\n",
      "\n",
      "      cardholder                hour  amount\n",
      "59            17 2018-01-07 20:35:00    2.50\n",
      "267           17 2018-01-28 19:30:38    0.72\n",
      "579           17 2018-03-02 02:48:43    3.12\n",
      "666           17 2018-03-09 00:13:59   18.11\n",
      "712           17 2018-03-12 05:29:57   22.49\n",
      "776           17 2018-03-18 19:05:54    2.94\n",
      "1089          17 2018-04-19 22:50:46    1.92\n",
      "1101          17 2018-04-21 05:01:18   14.95\n",
      "1108          17 2018-04-21 18:48:54   18.48\n",
      "1150          17 2018-04-26 21:24:12    3.69\n",
      "1155          17 2018-04-27 05:53:14   17.90\n",
      "1311          17 2018-05-14 03:38:11   17.40\n",
      "1346          17 2018-05-17 07:39:47    2.43\n",
      "1718          17 2018-06-25 16:31:00   17.90\n",
      "1868          17 2018-07-10 01:28:54    4.11\n",
      "2035          17 2018-07-26 16:02:22   15.06\n",
      "2061          17 2018-07-28 21:24:13    1.75\n",
      "2125          17 2018-08-05 20:20:23   18.67\n",
      "2341          17 2018-08-31 00:26:28   20.42\n",
      "2413          17 2018-09-09 19:03:51   16.92\n",
      "2431          17 2018-09-11 14:56:32    2.74\n",
      "2567          17 2018-09-25 12:53:26    1.95\n",
      "2753          17 2018-10-12 04:42:04   15.73\n",
      "2886          17 2018-10-26 21:47:56    2.45\n",
      "2942          17 2018-11-01 05:00:05   15.29\n",
      "3115          17 2018-11-19 23:25:26    2.35\n",
      "3127          17 2018-11-21 00:15:23    3.62\n",
      "3142          17 2018-11-22 14:29:40    3.85\n",
      "3279          17 2018-12-08 19:26:39   16.04\n",
      "3354          17 2018-12-16 17:00:56   16.44\n",
      "interquartile anamolies for cardhoder 3\n",
      "\n",
      "      cardholder                hour   amount\n",
      "142            3 2018-01-16 08:02:04    17.36\n",
      "186            3 2018-01-20 03:19:33    17.64\n",
      "421            3 2018-02-14 04:16:16    17.77\n",
      "575            3 2018-03-01 21:29:05  1119.00\n",
      "580            3 2018-03-02 03:35:56     4.40\n",
      "591            3 2018-03-02 18:53:41    15.95\n",
      "826            3 2018-03-23 18:20:40     3.41\n",
      "842            3 2018-03-25 08:27:43     5.17\n",
      "910            3 2018-04-01 01:48:11     1.71\n",
      "1360           3 2018-05-18 20:36:31    20.07\n",
      "1477           3 2018-05-31 15:00:56     3.81\n",
      "1704           3 2018-06-24 06:44:44     2.36\n",
      "1886           3 2018-07-11 16:55:22  1159.00\n",
      "1913           3 2018-07-14 06:09:18  1160.00\n",
      "2059           3 2018-07-28 10:07:18     5.41\n",
      "2090           3 2018-08-01 18:41:54     2.78\n",
      "2267           3 2018-08-21 19:56:37     4.62\n",
      "2268           3 2018-08-21 20:46:33   188.00\n",
      "2409           3 2018-09-09 03:39:06   626.00\n",
      "2483           3 2018-09-16 22:33:58     2.88\n",
      "2494           3 2018-09-18 03:15:30     5.10\n",
      "2533           3 2018-09-21 18:49:20     1.71\n",
      "2669           3 2018-10-05 08:27:56     1.36\n",
      "2702           3 2018-10-07 14:40:34   757.00\n",
      "2750           3 2018-10-11 23:29:33   206.00\n",
      "2811           3 2018-10-19 01:07:37  1053.00\n",
      "3122           3 2018-11-20 05:24:28  1054.00\n",
      "3272           3 2018-12-08 10:02:51     4.25\n",
      "3349           3 2018-12-16 08:22:39     5.05\n",
      "3472           3 2018-12-28 16:20:31   313.00\n"
     ]
    }
   ],
   "source": [
    "# Find anomalous transactions for 3 random card holders\n",
    "all_card_holder_df = get_customer_transaction()\n",
    "\n",
    "# get random sample in range of minumum cardholder id, and max cardholder id\n",
    "card_holder_sample =  random.sample(range(all_card_holder_df['cardholder'].min(), all_card_holder_df['cardholder'].max() +1), k=3)\n",
    "\n",
    "#loop thrugh range and print results\n",
    "#perhaps I could write a different function to work the data frame instead?? \n",
    "#function already exists, so goal is to finish homework :) \n",
    "for car_holder in card_holder_sample:\n",
    "    print (f\"interquartile anamolies for cardhoder {car_holder}\\n\")\n",
    "    print(find_int_quart_anamoly(car_holder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
